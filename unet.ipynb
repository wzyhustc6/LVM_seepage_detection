{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2bef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T21:50:51.595309Z",
     "start_time": "2023-04-26T21:50:49.813722Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from customlib import d2l\n",
    "from customlib import u2net\n",
    "from customlib import unet\n",
    "from customlib import loss_function as ls\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "from thop import profile\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"current device is\",device,torch.cuda.get_device_name())\n",
    "save_path='../model/'\n",
    "work_name=\"240506_u2net+samenc+aug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fcb51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T21:50:51.790632Z",
     "start_time": "2023-04-26T21:50:51.599127Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# batch_in, labels = list(iter(test_iter))[0]\n",
    "# batch_out = net(batch_in.cuda())\n",
    "# batch_out = torch.randn(3,2, 384, 384)\n",
    "# labels = (torch.randn (3,384, 384) > 0).long()\n",
    "# bce_dice_loss = ls.BCEDiceLoss()\n",
    "# print(\"iouloss     =  \" + str(ls.jaccard_loss(batch_out.cuda(), labels.cuda())))\n",
    "# print(\"celoss      =  \" + str(ls.ce_loss(batch_out.cuda(), labels.cuda()))) \n",
    "# print(\"diceloss    =  \" + str(ls.dice_loss(batch_out.cuda(), labels.cuda()))) \n",
    "# print(\"focalloss   =  \" + str(ls.focal_loss(batch_out.cuda(), labels.cuda())))\n",
    "# print(\"tverskyloss =  \" + str(ls.tversky_loss(batch_out.cuda(), labels.cuda())))\n",
    "# print(\"ce_iou      =  \" + str(ls.ceiou_loss(batch_out.cuda(), labels.cuda()))) \n",
    "# print(\"bce_dice      =  \" + str(bce_dice_loss(batch_out.cuda(), labels.cuda())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010ccf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T21:50:52.127344Z",
     "start_time": "2023-04-26T21:50:51.797349Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# net = fpn.FPNNet(num_classes=2)\n",
    "net = u2net.u2net_full(out_ch=2)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load(os.path.join(save_path,'{}'.format('best_240505_u2net+samenc+aug.pth')))\n",
    "net.eval()\n",
    "devices=d2l.try_all_gpus()\n",
    "net.to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SAM model weights\n",
    "sam_weights = torch.load('../model/sam_vit_b.pth')\n",
    "from functools import partial\n",
    "# Create the ImageEncoderViT model\n",
    "\n",
    "state_dict_new = net.tfenc.state_dict()\n",
    "\n",
    "# Create a new state dict in which we will load the weights\n",
    "state_dict_to_load = {}\n",
    "\n",
    "# Counters for successful and failed weight loads\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "\n",
    "# Iterate over the old state dict\n",
    "for name, param in sam_weights.items():\n",
    "    # Check if the weight name starts with 'image_encoder'\n",
    "    if name.startswith('image_encoder'):\n",
    "        # Remove the 'image_encoder.' prefix\n",
    "        new_name = name[len('image_encoder.'):]\n",
    "\n",
    "        # If the layer exists in the tfenc and the shapes match, load the weights\n",
    "        if new_name in state_dict_new and param.shape == state_dict_new[new_name].shape:\n",
    "            state_dict_to_load[new_name] = param\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f'Failed to load weight: {name}, shape: {param.shape}')\n",
    "            fail_count += 1\n",
    "\n",
    "# Load the weights into the tfenc\n",
    "net.tfenc.load_state_dict(state_dict_to_load, strict=False)\n",
    "\n",
    "# Print the counts\n",
    "print(f'Successfully loaded weights: {success_count}')\n",
    "print(f'Failed to load weights: {fail_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b54064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the old model\n",
    "model_old = torch.load(os.path.join(save_path,'{}.pth'.format(\"best_240505_u2net+samenc+aug\")))\n",
    "\n",
    "# Get the state dict of the old model\n",
    "state_dict_old = model_old.state_dict()\n",
    "\n",
    "# If the model was trained using DataParallel, remove the 'module.' prefix\n",
    "state_dict_old = {k.replace('module.', ''): v for k, v in state_dict_old.items()}\n",
    "\n",
    "# Get the state dict of the new model\n",
    "state_dict_new = net.state_dict()\n",
    "\n",
    "# Create a new state dict in which we will load the weights\n",
    "state_dict_to_load = {}\n",
    "\n",
    "# Counters for successful and failed weight loads\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "\n",
    "# Iterate over the old state dict\n",
    "for name, param in state_dict_old.items():\n",
    "    # If the layer exists in the new model and the shapes match, load the weights\n",
    "    if name in state_dict_new and param.shape == state_dict_new[name].shape:\n",
    "        state_dict_to_load[name] = param\n",
    "        success_count += 1\n",
    "    else:\n",
    "        # print(f'Failed to load weight: {name}, shape: {param.shape}')\n",
    "        fail_count += 1\n",
    "\n",
    "# Load the weights into the new model\n",
    "net.load_state_dict(state_dict_to_load, strict=False)\n",
    "\n",
    "# Print the counts\n",
    "print(f'Successfully loaded weights: {success_count}')\n",
    "print(f'Failed to load weights: {fail_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06b85e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T21:50:52.997494Z",
     "start_time": "2023-04-26T21:50:52.124925Z"
    },
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "X = torch.rand(size=(1, 3, 384, 384))\n",
    "flops, params = profile(net, inputs=(X,))\n",
    "print(net(X).shape)\n",
    "print(\"参数量：\", params/1e6, \"M\")\n",
    "print(\"FLOPS：\", flops/1e9, \"G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297c01a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T21:50:55.296517Z",
     "start_time": "2023-04-26T21:50:52.997713Z"
    },
    "origin_pos": 40,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size, crop_size = 4, (384, 384)\n",
    "train_iter,test_iter = d2l.load_data_voc(batch_size, crop_size,num_workers=4, is_new=True)\n",
    "# train_iter, test_iter = d2l.load_data_voc(batch_size, crop_size,num_workers=0,is_new=False)\n",
    "print(train_iter.dataset[0][0].shape)\n",
    "print(test_iter.dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36ff5b",
   "metadata": {
    "origin_pos": 44,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "num_epochs, lr, wd, devices = 200, 0.0001, 1e-4, d2l.try_all_gpus()\n",
    "savebest = 1\n",
    "# trainer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "trainer = torch.optim.AdamW(net.parameters(), lr=lr, weight_decay=wd)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(trainer, T_max=50)\n",
    "# trainer = torch.optim.RMSprop(net.parameters(), lr=0.001, alpha=0.99, eps=1e-08, weight_decay=wd)\n",
    "d2l.train_ch13_txt(net, train_iter, test_iter, ls.focal_rce_loss, trainer,scheduler, num_epochs, os.path.join(save_path,'{}.txt'.format(work_name)), work_name,savebest ,devices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
